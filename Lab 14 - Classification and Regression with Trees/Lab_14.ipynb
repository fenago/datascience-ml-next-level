{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification & Regression with Trees\n",
    "\n",
    "**Aim**: The aim of this notebook is to provide code-based examples for the implementation of tree based algorithms using scikit-learn. \n",
    "\n",
    "## Table of contents \n",
    "\n",
    "1. Decision Tree Classifier\n",
    "2. Random Forest Classifier\n",
    "3. AdaBoost Classifier\n",
    "4. Decision Tree Regressor\n",
    "5. Random Forest Regressor\n",
    "6. Gradient Boosted Trees Regressor \n",
    "7. Ensemble Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.externals.six import StringIO  \n",
    "from IPython.display import Image  \n",
    "from sklearn.tree import export_graphviz\n",
    "import pydotplus\n",
    "from sklearn import tree\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=Warning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Reading in the dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('fraud_prediction.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into training & test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the initial decision tree classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the DT classifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'gini', random_state = 50)\n",
    "\n",
    "#Fitting on the training data\n",
    "\n",
    "dt.fit(X_train, y_train)\n",
    "\n",
    "#Testing accuracy on the test data\n",
    "\n",
    "dt.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter Optimization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a grid of different hyper-parameters\n",
    "\n",
    "grid_params = {\n",
    "    'max_depth': [1,2,3,4,5,6],\n",
    "    'min_samples_leaf': [0.02,0.04, 0.06, 0.08]\n",
    "}\n",
    "\n",
    "#Building a 10 fold Cross Validated GridSearchCV object\n",
    "\n",
    "grid_object = GridSearchCV(estimator = dt, param_grid = grid_params, scoring = 'accuracy', cv = 10, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the grid to the training data\n",
    "\n",
    "grid_object.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best parameters\n",
    "\n",
    "grid_object.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best model\n",
    "\n",
    "dt = grid_object.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the data\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the DT classifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'gini', random_state = 50, max_depth= 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the classifier on the data\n",
    "\n",
    "dt.fit(features, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feature names\n",
    "\n",
    "feature_names = df.drop('isFraud', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the tree visualization\n",
    "\n",
    "data = tree.export_graphviz(dt, out_file=None, feature_names= feature_names.columns.values, proportion= True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(data) \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiliazing an Random Forest Classifier with default parameters\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state = 50)\n",
    "\n",
    "#Fitting the classifier on the training data\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "\n",
    "#Extracting the scores\n",
    "\n",
    "rf_classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-parameter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a grid of different hyper-parameters\n",
    "\n",
    "grid_params = {\n",
    "    'n_estimators': [300,400,500],\n",
    "    'max_depth': [1,2,3],\n",
    "    'min_samples_leaf': [0.05, 0.1, 0.2]\n",
    "}\n",
    "\n",
    "#Building a 3 fold Cross-Validated GridSearchCV object\n",
    "\n",
    "grid_object = GridSearchCV(estimator = rf_classifier, param_grid = grid_params, scoring = 'accuracy', \n",
    "                           cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the grid to the training data\n",
    "\n",
    "grid_object.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best parameters\n",
    "\n",
    "grid_object.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best model\n",
    "\n",
    "rf_best = grid_object.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adaboost Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into training & testing sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, \n",
    "                                                    stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the AdaBoost Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a tree (Decision Tree with max depth = 1)\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=1, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize an AdaBoost classifier with the tree as the base estimator\n",
    "\n",
    "ada_boost = AdaBoostClassifier(base_estimator = dt, n_estimators=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the AdaBoost classifier to the training set\n",
    "\n",
    "ada_boost.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the accuracy scores from the classifier\n",
    "\n",
    "ada_boost.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Hyper-paramter tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a grid of hyper-parameters\n",
    "\n",
    "grid_params = {\n",
    "    'n_estimators': [100,200,300]\n",
    "}\n",
    "\n",
    "#Building a 3 fold CV GridSearchCV object\n",
    "\n",
    "grid_object = GridSearchCV(estimator = ada_boost, param_grid = grid_params, scoring = 'accuracy', cv = 3, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the grid to the training data\n",
    "\n",
    "grid_object.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best parameters\n",
    "\n",
    "grid_object.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the best model\n",
    "\n",
    "ada_best = grid_object.best_estimator_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Tree Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('amount', axis = 1).values\n",
    "target = df['amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the decison tree regressor \n",
    "\n",
    "dt_reg = DecisionTreeRegressor(max_depth = 10, min_samples_leaf = 0.2, random_state= 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fitting the tree to the training data\n",
    "\n",
    "dt_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Visualizing the decision tree**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting the feature names\n",
    "\n",
    "feature_names = df.drop('amount', axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the tree visualization\n",
    "\n",
    "data = tree.export_graphviz(dt_reg, out_file=None, feature_names= feature_names.columns.values, proportion= True)\n",
    "\n",
    "graph = pydotplus.graph_from_dot_data(data) \n",
    "\n",
    "# Show graph\n",
    "Image(graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest Regressor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('amount', axis = 1).values\n",
    "target = df['amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiliazing an Random Forest Regressor with default parameters\n",
    "\n",
    "rf_reg = RandomForestRegressor(max_depth = 10, min_samples_leaf = 0.2, random_state = 50)\n",
    "\n",
    "#Fitting the Regressor on the training data\n",
    "\n",
    "rf_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosted Trees for regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('amount', axis = 1).values\n",
    "target = df['amount'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the Gradient Boosted Regressor**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiliazing an Gradient Boosted Regressor with default parameters\n",
    "\n",
    "gb_reg = GradientBoostingRegressor(max_depth = 5, n_estimators = 100, learning_rate = 0.1, random_state = 50)\n",
    "\n",
    "#Fitting the regressor on the training data\n",
    "\n",
    "gb_reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ensemble Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading in the dataset\n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')\n",
    "\n",
    "#Dropping the index\n",
    "\n",
    "df = df.drop(['Unnamed: 0'], axis = 1)\n",
    "\n",
    "#Splitting the data into training and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building the DT & RF classifier to include in the Voting Classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing the DT classifier\n",
    "\n",
    "dt = DecisionTreeClassifier(criterion = 'gini', random_state = 50)\n",
    "\n",
    "#Fitting on the training data\n",
    "\n",
    "dt.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initiliazing an Random Forest Classifier with default parameters\n",
    "\n",
    "rf_classifier = RandomForestClassifier(random_state = 50)\n",
    "\n",
    "#Fitting the classifier on the training data\n",
    "\n",
    "rf_classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating a list of models\n",
    "\n",
    "models = [('Decision Tree', dt), ('Random Forest', rf_classifier)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize a voting classifier \n",
    "\n",
    "voting_model = VotingClassifier(estimators = models)\n",
    "\n",
    "#Fitting the model to the training data\n",
    "\n",
    "voting_model.fit(X_train, y_train)\n",
    "\n",
    "#Evaluating the accuracy on the test data\n",
    "\n",
    "voting_model.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
