{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cathedral-directory",
   "metadata": {},
   "source": [
    "### Plotly Lab - ML Regression\n",
    "\n",
    "This Notebook shows how to use Plotly charts for displaying various types of regression models, starting from simple models like [Linear Regression](https://scikit-learn.org/stable/auto_examples/linear_model/plot_ols.html), and progressively move towards models like [Decision Tree][tree] and [Polynomial Features][poly].\n",
    "\n",
    "We will use [Scikit-learn](https://scikit-learn.org/) to split and preprocess our data and train various regression models. Scikit-learn is a popular Machine Learning (ML) library that offers various tools for creating and training ML algorithms, feature engineering, data cleaning, and evaluating and testing models. It was designed to be accessible, and to work seamlessly with popular libraries like NumPy and Pandas.\n",
    "\n",
    "\n",
    "[lasso]: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LassoCV.html\n",
    "[tree]: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeRegressor.html\n",
    "[poly]: https://scikit-learn.org/stable/modules/generated/sklearn.preprocessing.PolynomialFeatures.html"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cathedral-quebec",
   "metadata": {},
   "source": [
    "## Basic linear regression plots\n",
    "\n",
    "In this section, we show you how to apply a simple regression model for predicting tips a server will receive based on various client attributes (such as sex, time of the week, and whether they are a smoker).\n",
    "\n",
    "We will be using the [Linear Regression][lr], which is a simple model that fit an intercept (the mean tip received by a server), and add a slope for each feature we use, such as the value of the total bill. We show you how to do that with both Plotly Express and Scikit-learn.\n",
    "\n",
    "### Ordinary Least Square (OLS) with `plotly.express`\n",
    "\n",
    "This example shows [how to use `plotly.express`'s `trendline` parameter to train a simply Ordinary Least Square (OLS)](/python/linear-fits/) for predicting the tips waiters will receive based on the value of the total bill.\n",
    "\n",
    "[lr]: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "headed-arbitration",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "\n",
    "df = px.data.tips()\n",
    "fig = px.scatter(\n",
    "    df, x='total_bill', y='tip', opacity=0.65,\n",
    "    trendline='ols', trendline_color_override='darkblue'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "determined-convention",
   "metadata": {},
   "source": [
    "### Linear Regression with scikit-learn\n",
    "\n",
    "You can also perform the same prediction using scikit-learn's `LinearRegression`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rental-annual",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = px.data.tips()\n",
    "X = df.total_bill.values.reshape(-1, 1)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, df.tip)\n",
    "\n",
    "x_range = np.linspace(X.min(), X.max(), 100)\n",
    "y_range = model.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "fig = px.scatter(df, x='total_bill', y='tip', opacity=0.65)\n",
    "fig.add_traces(go.Scatter(x=x_range, y=y_range, name='Regression Fit'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "corporate-wonder",
   "metadata": {},
   "source": [
    "### ML Regression in Dash\n",
    "\n",
    "[Dash](https://plotly.com/dash/) is the best way to build analytical apps in Python using Plotly figures. To run the app below, run `pip install dash`, click \"Download\" to get the code and run `python app.py`.\n",
    "\n",
    "Get started  with [the official Dash docs](https://dash.plotly.com/installation) and **learn how to effortlessly [style](https://plotly.com/dash/design-kit/) & [deploy](https://plotly.com/dash/app-manager/) apps like this with <a class=\"plotly-red\" href=\"https://plotly.com/dash/\">Dash Enterprise</a>.**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "antique-bridal",
   "metadata": {
    "hide_code": true
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame\n",
    "snippet_url = 'https://dash-gallery.plotly.host/python-docs-dash-snippets/'\n",
    "IFrame(snippet_url + 'ml-regression', width='100%', height=630)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "professional-election",
   "metadata": {},
   "source": [
    "## Model generalization on unseen data\n",
    "\n",
    "With `go.Scatter`, you can easily color your plot based on a predefined data split. By coloring the training and the testing data points with different colors, you can easily see if whether the model generalizes well to the test data or not."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "blessed-musician",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = px.data.tips()\n",
    "X = df.total_bill[:, None]\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df.tip, random_state=0)\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "x_range = np.linspace(X.min(), X.max(), 100)\n",
    "y_range = model.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(x=X_train.squeeze(), y=y_train, name='train', mode='markers'),\n",
    "    go.Scatter(x=X_test.squeeze(), y=y_test, name='test', mode='markers'),\n",
    "    go.Scatter(x=x_range, y=y_range, name='prediction')\n",
    "])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suffering-target",
   "metadata": {},
   "source": [
    "## Comparing different kNN models parameters\n",
    "\n",
    "In addition to linear regression, it's possible to fit the same data using [k-Nearest Neighbors][knn]. When you perform a prediction on a new sample, this model either takes the weighted or un-weighted average of the neighbors. In order to see the difference between those two averaging options, we train a kNN model with both of those parameters, and we plot them in the same way as the previous graph.\n",
    "\n",
    "Notice how we can combine scatter points with lines using Plotly.py. You can learn more about [multiple chart types](https://plotly.com/python/graphing-multiple-chart-types/).\n",
    "\n",
    "[knn]: https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsRegressor.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "engaged-bathroom",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "\n",
    "df = px.data.tips()\n",
    "X = df.total_bill.values.reshape(-1, 1)\n",
    "x_range = np.linspace(X.min(), X.max(), 100)\n",
    "\n",
    "# Model #1\n",
    "knn_dist = KNeighborsRegressor(10, weights='distance')\n",
    "knn_dist.fit(X, df.tip)\n",
    "y_dist = knn_dist.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "# Model #2\n",
    "knn_uni = KNeighborsRegressor(10, weights='uniform')\n",
    "knn_uni.fit(X, df.tip)\n",
    "y_uni = knn_uni.predict(x_range.reshape(-1, 1))\n",
    "\n",
    "fig = px.scatter(df, x='total_bill', y='tip', color='sex', opacity=0.65)\n",
    "fig.add_traces(go.Scatter(x=x_range, y=y_uni, name='Weights: Uniform'))\n",
    "fig.add_traces(go.Scatter(x=x_range, y=y_dist, name='Weights: Distance'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "living-charger",
   "metadata": {},
   "source": [
    "## Displaying `PolynomialFeatures` using $\\LaTeX$\n",
    "\n",
    "Notice how linear regression fits a straight line, but kNN can take non-linear shapes. Moreover, it is possible to extend linear regression to polynomial regression by using scikit-learn's `PolynomialFeatures`, which lets you fit a slope for your features raised to the power of `n`, where `n=1,2,3,4` in our example.\n",
    "\n",
    "\n",
    "With Plotly, it's easy to display latex equations in legend and titles by simply adding `$` before and after your equation. This way, you can see the coefficients that our polynomial regression fitted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "appointed-duplicate",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "def format_coefs(coefs):\n",
    "    equation_list = [f\"{coef}x^{i}\" for i, coef in enumerate(coefs)]\n",
    "    equation = \"$\" +  \" + \".join(equation_list) + \"$\"\n",
    "\n",
    "    replace_map = {\"x^0\": \"\", \"x^1\": \"x\", '+ -': '- '}\n",
    "    for old, new in replace_map.items():\n",
    "        equation = equation.replace(old, new)\n",
    "\n",
    "    return equation\n",
    "\n",
    "df = px.data.tips()\n",
    "X = df.total_bill.values.reshape(-1, 1)\n",
    "x_range = np.linspace(X.min(), X.max(), 100).reshape(-1, 1)\n",
    "\n",
    "fig = px.scatter(df, x='total_bill', y='tip', opacity=0.65)\n",
    "for degree in [1, 2, 3, 4]:\n",
    "    poly = PolynomialFeatures(degree)\n",
    "    poly.fit(X)\n",
    "    X_poly = poly.transform(X)\n",
    "    x_range_poly = poly.transform(x_range)\n",
    "\n",
    "    model = LinearRegression(fit_intercept=False)\n",
    "    model.fit(X_poly, df.tip)\n",
    "    y_poly = model.predict(x_range_poly)\n",
    "\n",
    "    equation = format_coefs(model.coef_.round(2))\n",
    "    fig.add_traces(go.Scatter(x=x_range.squeeze(), y=y_poly, name=equation))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "coupled-forty",
   "metadata": {},
   "source": [
    "## 3D regression surface with `px.scatter_3d` and `go.Surface`\n",
    "\n",
    "Visualize the decision plane of your model whenever you have more than one variable in your input data. Here, we will use [`sklearn.svm.SVR`](https://scikit-learn.org/stable/modules/generated/sklearn.svm.SVR.html), which is a Support Vector Machine (SVM) model specifically designed for regression."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "judicial-lecture",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.svm import SVR\n",
    "\n",
    "mesh_size = .02\n",
    "margin = 0\n",
    "\n",
    "df = px.data.iris()\n",
    "\n",
    "X = df[['sepal_width', 'sepal_length']]\n",
    "y = df['petal_width']\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "model = SVR(C=1.)\n",
    "model.fit(X, y)\n",
    "\n",
    "# Create a mesh grid on which we will run our model\n",
    "x_min, x_max = X.sepal_width.min() - margin, X.sepal_width.max() + margin\n",
    "y_min, y_max = X.sepal_length.min() - margin, X.sepal_length.max() + margin\n",
    "xrange = np.arange(x_min, x_max, mesh_size)\n",
    "yrange = np.arange(y_min, y_max, mesh_size)\n",
    "xx, yy = np.meshgrid(xrange, yrange)\n",
    "\n",
    "# Run model\n",
    "pred = model.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "pred = pred.reshape(xx.shape)\n",
    "\n",
    "# Generate the plot\n",
    "fig = px.scatter_3d(df, x='sepal_width', y='sepal_length', z='petal_width')\n",
    "fig.update_traces(marker=dict(size=5))\n",
    "fig.add_traces(go.Surface(x=xrange, y=yrange, z=pred, name='pred_surface'))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "annoying-ethiopia",
   "metadata": {},
   "source": [
    "## Visualizing coefficients for multiple linear regression (MLR)\n",
    "\n",
    "Visualizing regression with one or two variables is straightforward, since we can respectively plot them with scatter plots and 3D scatter plots. Moreover, if you have more than 2 features, you will need to find alternative ways to visualize your data.\n",
    "\n",
    "One way is to use [bar charts](https://plotly.com/python/bar-charts/). In our example, each bar indicates the coefficients of our linear regression model for each input feature. Our model was trained on the [Iris dataset](https://archive.ics.uci.edu/ml/datasets/iris)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "satisfactory-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = px.data.iris()\n",
    "\n",
    "X = df.drop(columns=['petal_width', 'species_id'])\n",
    "X = pd.get_dummies(X, columns=['species'], prefix_sep='=')\n",
    "y = df['petal_width']\n",
    "\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "\n",
    "colors = ['Positive' if c > 0 else 'Negative' for c in model.coef_]\n",
    "\n",
    "fig = px.bar(\n",
    "    x=X.columns, y=model.coef_, color=colors,\n",
    "    color_discrete_sequence=['red', 'blue'],\n",
    "    labels=dict(x='Feature', y='Linear coefficient'),\n",
    "    title='Weight of each feature for predicting petal width'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-major",
   "metadata": {},
   "source": [
    "## Prediction Error Plots\n",
    "\n",
    "When you are working with very high-dimensional data, it is inconvenient to plot every dimension with your output `y`. Instead, you can use methods such as prediction error plots, which let you visualize how well your model does compared to the ground truth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-villa",
   "metadata": {},
   "source": [
    "### Simple actual vs predicted plot\n",
    "\n",
    "This example shows you the simplest way to compare the predicted output vs. the actual output. A good model will have most of the scatter dots near the diagonal black line."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "inclusive-policy",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "df = px.data.iris()\n",
    "X = df[['sepal_width', 'sepal_length']]\n",
    "y = df['petal_width']\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "model = LinearRegression()\n",
    "model.fit(X, y)\n",
    "y_pred = model.predict(X)\n",
    "\n",
    "fig = px.scatter(x=y, y=y_pred, labels={'x': 'ground truth', 'y': 'prediction'})\n",
    "fig.add_shape(\n",
    "    type=\"line\", line=dict(dash='dash'),\n",
    "    x0=y.min(), y0=y.min(),\n",
    "    x1=y.max(), y1=y.max()\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "romance-hartford",
   "metadata": {},
   "source": [
    "### Enhanced prediction error analysis using `plotly.express`\n",
    "\n",
    "Add marginal histograms to quickly diagnoses any prediction bias your model might have. The built-in `OLS` functionality let you visualize how well your model generalizes by comparing it with the theoretical optimal fit (black dotted line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "thousand-resort",
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = px.data.iris()\n",
    "\n",
    "# Split data into training and test splits\n",
    "train_idx, test_idx = train_test_split(df.index, test_size=.25, random_state=0)\n",
    "df['split'] = 'train'\n",
    "df.loc[test_idx, 'split'] = 'test'\n",
    "\n",
    "X = df[['sepal_width', 'sepal_length']]\n",
    "y = df['petal_width']\n",
    "X_train = df.loc[train_idx, ['sepal_width', 'sepal_length']]\n",
    "y_train = df.loc[train_idx, 'petal_width']\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "df['prediction'] = model.predict(X)\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x='petal_width', y='prediction',\n",
    "    marginal_x='histogram', marginal_y='histogram',\n",
    "    color='split', trendline='ols'\n",
    ")\n",
    "fig.update_traces(histnorm='probability', selector={'type':'histogram'})\n",
    "fig.add_shape(\n",
    "    type=\"line\", line=dict(dash='dash'),\n",
    "    x0=y.min(), y0=y.min(),\n",
    "    x1=y.max(), y1=y.max()\n",
    ")\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "portuguese-daughter",
   "metadata": {},
   "source": [
    "## Residual plots\n",
    "\n",
    "Just like prediction error plots, it's easy to visualize your prediction residuals in just a few lines of codes using `plotly.express` built-in capabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unnecessary-samoa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df = px.data.iris()\n",
    "\n",
    "# Split data into training and test splits\n",
    "train_idx, test_idx = train_test_split(df.index, test_size=.25, random_state=0)\n",
    "df['split'] = 'train'\n",
    "df.loc[test_idx, 'split'] = 'test'\n",
    "\n",
    "X = df[['sepal_width', 'sepal_length']]\n",
    "X_train = df.loc[train_idx, ['sepal_width', 'sepal_length']]\n",
    "y_train = df.loc[train_idx, 'petal_width']\n",
    "\n",
    "# Condition the model on sepal width and length, predict the petal width\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "df['prediction'] = model.predict(X)\n",
    "df['residual'] = df['prediction'] - df['petal_width']\n",
    "\n",
    "fig = px.scatter(\n",
    "    df, x='prediction', y='residual',\n",
    "    marginal_y='violin',\n",
    "    color='split', trendline='ols'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "champion-speed",
   "metadata": {},
   "source": [
    "## Visualize regularization across cross-validation folds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "driven-consistency",
   "metadata": {},
   "source": [
    "In this example, we show how to plot the results of various $\\alpha$ penalization values from the results of cross-validation using scikit-learn's `LassoCV`. This is useful to see how much the error of the optimal alpha actually varies across CV folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "smoking-deficit",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "N_FOLD = 6\n",
    "\n",
    "# Load and preprocess the data\n",
    "df = px.data.gapminder()\n",
    "X = df.drop(columns=['lifeExp', 'iso_num'])\n",
    "X = pd.get_dummies(X, columns=['country', 'continent', 'iso_alpha'])\n",
    "y = df['lifeExp']\n",
    "\n",
    "# Train model to predict life expectancy\n",
    "model = LassoCV(cv=N_FOLD, normalize=True)\n",
    "model.fit(X, y)\n",
    "mean_alphas = model.mse_path_.mean(axis=-1)\n",
    "\n",
    "fig = go.Figure([\n",
    "    go.Scatter(\n",
    "        x=model.alphas_, y=model.mse_path_[:, i],\n",
    "        name=f\"Fold: {i+1}\", opacity=.5, line=dict(dash='dash'),\n",
    "        hovertemplate=\"alpha: %{x} <br>MSE: %{y}\"\n",
    "    )\n",
    "    for i in range(N_FOLD)\n",
    "])\n",
    "fig.add_traces(go.Scatter(\n",
    "    x=model.alphas_, y=mean_alphas,\n",
    "    name='Mean', line=dict(color='black', width=3),\n",
    "    hovertemplate=\"alpha: %{x} <br>MSE: %{y}\",\n",
    "))\n",
    "\n",
    "fig.add_shape(\n",
    "    type=\"line\", line=dict(dash='dash'),\n",
    "    x0=model.alpha_, y0=0,\n",
    "    x1=model.alpha_, y1=1,\n",
    "    yref='paper'\n",
    ")\n",
    "\n",
    "fig.update_layout(\n",
    "    xaxis_title='alpha',\n",
    "    xaxis_type=\"log\",\n",
    "    yaxis_title=\"Mean Square Error (MSE)\"\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "checked-nurse",
   "metadata": {},
   "source": [
    "## Grid search visualization using `px.density_heatmap` and `px.box`\n",
    "\n",
    "In this example, we show how to visualize the results of a grid search on a `DecisionTreeRegressor`. The first plot shows how to visualize the score of each model parameter on individual splits (grouped using facets). The second plot aggregates the results of all splits such that each box represents a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceramic-affiliation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "N_FOLD = 6\n",
    "\n",
    "# Load and shuffle dataframe\n",
    "df = px.data.iris()\n",
    "df = df.sample(frac=1, random_state=0)\n",
    "\n",
    "X = df[['sepal_width', 'sepal_length']]\n",
    "y = df['petal_width']\n",
    "\n",
    "# Define and fit the grid\n",
    "model = DecisionTreeRegressor()\n",
    "param_grid = {\n",
    "    'criterion': ['mse', 'friedman_mse', 'mae'],\n",
    "    'max_depth': range(2, 5)\n",
    "}\n",
    "grid = GridSearchCV(model, param_grid, cv=N_FOLD)\n",
    "grid.fit(X, y)\n",
    "grid_df = pd.DataFrame(grid.cv_results_)\n",
    "\n",
    "# Convert the wide format of the grid into the long format\n",
    "# accepted by plotly.express\n",
    "melted = (\n",
    "    grid_df\n",
    "    .rename(columns=lambda col: col.replace('param_', ''))\n",
    "    .melt(\n",
    "        value_vars=[f'split{i}_test_score' for i in range(N_FOLD)],\n",
    "        id_vars=['mean_test_score', 'mean_fit_time', 'criterion', 'max_depth'],\n",
    "        var_name=\"cv_split\",\n",
    "        value_name=\"r_squared\"\n",
    "    )\n",
    ")\n",
    "\n",
    "# Format the variable names for simplicity\n",
    "melted['cv_split'] = (\n",
    "    melted['cv_split']\n",
    "    .str.replace('_test_score', '')\n",
    "    .str.replace('split', '')\n",
    ")\n",
    "\n",
    "# Single function call to plot each figure\n",
    "fig_hmap = px.density_heatmap(\n",
    "    melted, x=\"max_depth\", y='criterion',\n",
    "    histfunc=\"sum\", z=\"r_squared\",\n",
    "    title='Grid search results on individual fold',\n",
    "    hover_data=['mean_fit_time'],\n",
    "    facet_col=\"cv_split\", facet_col_wrap=3,\n",
    "    labels={'mean_test_score': \"mean_r_squared\"}\n",
    ")\n",
    "\n",
    "fig_box = px.box(\n",
    "    melted, x='max_depth', y='r_squared',\n",
    "    title='Grid search results ',\n",
    "    hover_data=['mean_fit_time'],\n",
    "    points='all',\n",
    "    color=\"criterion\",\n",
    "    hover_name='cv_split',\n",
    "    labels={'mean_test_score': \"mean_r_squared\"}\n",
    ")\n",
    "\n",
    "# Display\n",
    "fig_hmap.show()\n",
    "fig_box.show()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "notebook_metadata_filter": "all",
   "text_representation": {
    "extension": ".md",
    "format_name": "markdown",
    "format_version": "1.3",
    "jupytext_version": "1.11.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "plotly": {
   "description": "Visualize regression in scikit-learn with Plotly.",
   "display_as": "ai_ml",
   "language": "python",
   "layout": "base",
   "name": "ML Regression",
   "order": 1,
   "page_type": "u-guide",
   "permalink": "python/ml-regression/",
   "thumbnail": "thumbnail/ml-regression.png"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
