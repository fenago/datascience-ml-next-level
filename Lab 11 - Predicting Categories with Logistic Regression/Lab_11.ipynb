{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting categories with Logistic Regression\n",
    "\n",
    "**Aim**: The aim of this notebook is to predict if a mobile transaction is fraudulent or not by using the logistic regression algorithm with scikit-learn.\n",
    "\n",
    "## Table of contents\n",
    "\n",
    "2. Implementing the logistic regression algorithm\n",
    "3. Fine-tuning parameters using GridsearchCV\n",
    "4. Scaling\n",
    "5. Interpreting the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Package Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import linear_model\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading in the dataset \n",
    "\n",
    "df = pd.read_csv('fraud_prediction.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing the logistic regression algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Splitting the data into training and test sets**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating the features \n",
    "\n",
    "features = df.drop('isFraud', axis = 1).values\n",
    "target = df['isFraud'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, target, test_size = 0.3, random_state = 42, stratify = target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating and evaluating the base classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an logistic regression object\n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression()\n",
    "\n",
    "#Fitting the model to the training and test sets\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score of the logistic regression model\n",
    "\n",
    "logistic_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tuning parameters using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Building the model with L1 penality \n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression(penalty='l1')\n",
    "\n",
    "#Using GridSearchCV to search for the best parameter\n",
    "\n",
    "grid = GridSearchCV(logistic_regression, {'C':[0.0001, 0.001, 0.01, 0.1, 10]})\n",
    "grid.fit(X_train, y_train)\n",
    "\n",
    "# Print out the best parameter\n",
    "\n",
    "print(\"The most optimal inverse regularization strength is:\", grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initializing an logistic regression object\n",
    "\n",
    "logistic_regression = linear_model.LogisticRegression(C = 10, penalty = 'l1')\n",
    "\n",
    "#Fitting the model to the training and test sets\n",
    "\n",
    "logistic_regression.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Accuracy score of the logistic regression model\n",
    "\n",
    "logistic_regression.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "C_list = [0.0001, 0.001, 0.01, 0.1, 10, 100, 1000]\n",
    "\n",
    "# Evaluate the training and test classification errors for each value of C\n",
    "\n",
    "for value in C_list:\n",
    "    \n",
    "    # Create LogisticRegression object and fit\n",
    "    logistic_regression = linear_model.LogisticRegression(C= value, penalty = 'l1')\n",
    "    logistic_regression.fit(X_train, y_train)\n",
    "    \n",
    "    # Evaluate error rates and append to lists\n",
    "    train_errors.append(logistic_regression.score(X_train, y_train) )\n",
    "    test_errors.append(logistic_regression.score(X_test, y_test))\n",
    "    \n",
    "# Plot results\n",
    "plt.semilogx(C_list, train_errors, C_list, test_errors)\n",
    "plt.legend((\"train\", \"test\"))\n",
    "plt.ylabel('Accuracy Score')\n",
    "plt.xlabel('C (Inverse regularization strength)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scaling your data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting up the scaling pipeline \n",
    "\n",
    "pipeline_order = [('scaler', StandardScaler()), ('logistic_reg', linear_model.LogisticRegression(C = 10, penalty = 'l1'))]\n",
    "\n",
    "pipeline = Pipeline(pipeline_order)\n",
    "\n",
    "#Fitting the classfier to the scaled dataset \n",
    "\n",
    "logistic_regression_scaled = pipeline.fit(X_train, y_train)\n",
    "\n",
    "#Extracting the score \n",
    "\n",
    "logistic_regression_scaled.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interpreting the results of the model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing out the coefficients of each variable \n",
    "\n",
    "print(logistic_regression.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Printing out the intercept of the model\n",
    "\n",
    "print(logistic_regression.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
